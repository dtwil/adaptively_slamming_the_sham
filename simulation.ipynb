{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from cmdstanpy import CmdStanModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we repeat the analysis that was done in the original simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>sham_n</th>\n",
       "      <th>sham_est</th>\n",
       "      <th>sham_se</th>\n",
       "      <th>exposed_n</th>\n",
       "      <th>exposed_est</th>\n",
       "      <th>exposed_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.041</td>\n",
       "      <td>32</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.042</td>\n",
       "      <td>36</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>32</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.032</td>\n",
       "      <td>32</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.040</td>\n",
       "      <td>32</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq  sham_n  sham_est  sham_se  exposed_n  exposed_est  exposed_se\n",
       "0     1      32    -0.005    0.041         32        0.036       0.041\n",
       "1    15      32     0.013    0.042         36        0.173       0.034\n",
       "2    30      32     0.033    0.032         32        0.107       0.035\n",
       "3    45      32    -0.010    0.032         32        0.181       0.052\n",
       "4    60      32    -0.002    0.040         32        0.136       0.044"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicks = pd.read_table(\"chickens.dat\", sep=\"\\\\s+\")\n",
    "chicks[\"exposed_est\"] -= 1\n",
    "chicks[\"sham_est\"] -= 1\n",
    "chicks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:07:42 - cmdstanpy - INFO - CmdStan start processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acbc7d75b0341d184c685a83deeace5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a328dd00451840c48aa41774dadccf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023739880faa406cb6df9450e2c021fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352eee63cc634170a78f9d560ed54110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:07:42 - cmdstanpy - INFO - CmdStan done processing.\n",
      "15:07:42 - cmdstanpy - WARNING - Non-fatal error during sampling:\n",
      "Exception: normal_lpdf: Location parameter[1] is inf, but must be finite! (in 'dynamic_hier.stan', line 28, column 4 to column 57)\n",
      "\tException: normal_lpdf: Location parameter[1] is inf, but must be finite! (in 'dynamic_hier.stan', line 28, column 4 to column 57)\n",
      "Consider re-running with show_console=True if the above output is unclear!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chick_model = CmdStanModel(stan_file=\"dynamic_hier.stan\")\n",
    "chick_data = {\n",
    "    \"num_expts\": len(chicks),\n",
    "    \"avg_treated_response\": chicks[\"exposed_est\"],\n",
    "    \"avg_control_response\": chicks[\"sham_est\"],\n",
    "    \"treated_se\": chicks[\"exposed_se\"],\n",
    "    \"control_se\": chicks[\"sham_se\"],\n",
    "    \"expt_id\": list(range(1, len(chicks) + 1)),\n",
    "}\n",
    "chick_fit = chick_model.sample(data=chick_data, adapt_delta=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below simulates a dataset for `num_experiments` experiments, all assumed to have the same proportion `prop_treatment` allocated to the treatment group. Here one complication is that the original simulation assumes all experiments have the same number of subjects in the control and treatment groups.\n",
    "\n",
    "The original assumptions are:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    y_{j1} \\mid \\theta_j, b_j &\\sim N(\\theta_j + b_j, s_{j1}) \\\\\n",
    "    y_{j0} \\mid b_j &\\sim N(b_j, s_{j0}) \\\\\n",
    "    \\theta_j &\\sim N(\\mu_\\theta, \\sigma_\\theta) \\\\\n",
    "    b_j &\\sim N(\\mu_b, \\sigma_b)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "These assumptions mostly still work here since $s_{j1}$ and $s_{j0}$ need not be the same for all experiments $j$. However, in the original simulation, it was assumed that $s_{j1} = s_{j0} = 0.04$ for all $j$. This is reasonable if the treatment and control groups have the same size and if we expect the treatment/sham effects to have similar spread, which was empirically shown for the chicken dataset. \n",
    "\n",
    "However, if the groups have unequal numbers of subjects, then we expect the group with fewer subjects to have higher variance. We let $Y_{j0}^{(i)}$ and $Y_{j1}^{(k)}$ be the outcomes for the $i$-th and $k$-th individuals in the control and treatment groups respectively for experiment $j$. Let the $j$-th experiment have $N_{j0}$ and $N_{j1}$ subjects in control and treatment groups respectively. If the number of subjects in each group is at least 30, then assuming the individual outcomes are iid, the CLT gives\n",
    "\n",
    "$$ y_{j1} = \\frac{1}{N_{j1}} \\sum_{k=1}^{N_{j1}} Y_{j1}^{(k)} \\rightarrow N(\\mu_{j1}, \\sigma_{j1}) $$\n",
    "\n",
    "where $\\sigma_{j1} = \\sqrt{\\frac{\\text{var}(Y_{j1})}{N_{j1}}}$ and similarly for $y_{j0}$. We identify $\\mu_{j1}$ with $\\theta_j + b_j$ and $\\sigma_{j1}$ with $s_{j1}$. Since $s_{j1} = 0.04$ in the original simulation, we use $\\text{var}(Y_{j1}) = 32 \\times (0.04)^2$ for all experiments $j$; likewise for $\\text{var}(Y_{j0})$.\n",
    "\n",
    "*Thought: What if the sample sizes are too small for the CLT? Maybe bootstrap or make distributional assumptions on $Y_{j1}^{(k)}$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_expts_with_prop(\n",
    "    num_subjects_per_expt,\n",
    "    prop_treatment,\n",
    "    mu_b,\n",
    "    mu_theta,\n",
    "    sigma_b,\n",
    "    sigma_theta,\n",
    "    sigma_treatment,\n",
    "    sigma_control,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic data with a specified proportion of treated subjects.\n",
    "\n",
    "    Args:\n",
    "    num_subjects_per_expt: A list of integers, the number of subjects in each\n",
    "        experiment.\n",
    "    prop_treatment: A float, the proportion of subjects that are treated.\n",
    "    mu_b: A float, the true (mean) of the control group response.\n",
    "    mu_theta: A float, the true (mean) treatment effect.\n",
    "    sigma_b: A float, the standard deviation of b_j.\n",
    "    sigma_theta: A float, the standard deviation of theta_j.\n",
    "    sigma_treatment: A float, the standard deviation of the treated group\n",
    "        response.\n",
    "    sigma_control: A float, the standard deviation of the control group\n",
    "        response.\n",
    "    \"\"\"\n",
    "    assert len(num_subjects_per_expt) == len(prop_treatment)\n",
    "    assert sigma_theta >= 0 and sigma_b >= 0\n",
    "    assert sigma_treatment >= 0 and sigma_control >= 0\n",
    "\n",
    "    num_expts = len(num_subjects_per_expt)\n",
    "    num_treated = np.floor(prop_treatment * num_subjects_per_expt).astype(int)\n",
    "    num_control = num_subjects_per_expt - num_treated\n",
    "\n",
    "    sigma_y1 = sigma_treatment / np.sqrt(num_treated)\n",
    "    sigma_y0 = sigma_control / np.sqrt(num_control)\n",
    "\n",
    "    theta = np.random.normal(mu_theta, sigma_theta, num_expts)\n",
    "    b = np.random.normal(mu_b, sigma_b, num_expts)\n",
    "\n",
    "    return {\n",
    "        \"true_params\": {\n",
    "            \"mu_b\": mu_b,\n",
    "            \"mu_theta\": mu_theta,\n",
    "            \"sigma_b\": sigma_b,\n",
    "            \"sigma_theta\": sigma_theta,\n",
    "            \"sigma_treatment\": sigma_treatment,\n",
    "            \"sigma_control\": sigma_control,\n",
    "        },\n",
    "        \"num_expts\": len(num_subjects_per_expt),\n",
    "        \"avg_treated_response\": np.random.normal(theta + b, sigma_y1),\n",
    "        \"avg_control_response\": np.random.normal(b, sigma_y0),\n",
    "        \"treated_se\": sigma_y1,\n",
    "        \"control_se\": sigma_y0,\n",
    "        \"expt_id\": list(range(1, num_expts + 1)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_inferences(data, estimate, se, conf_lower, conf_upper):\n",
    "    # an observation is significant if 0 is not in the interval\n",
    "    significant = ~((conf_lower < 0) & (0 < conf_upper))\n",
    "    correct_sign = np.sign(data[\"true_params\"][\"mu_theta\"]) == np.sign(estimate)\n",
    "    error = data[\"true_params\"][\"mu_theta\"] - estimate\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"estimate\": estimate,\n",
    "            \"se\": se,\n",
    "            \"conf_lower\": conf_lower,\n",
    "            \"conf_upper\": conf_upper,\n",
    "            \"is_signif\": significant,\n",
    "            \"correct_sign\": correct_sign,\n",
    "            \"error\": error,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def get_exposed_only_inferences(data, alpha=0.05):\n",
    "    z_value = stats.norm.ppf(1 - alpha / 2)\n",
    "    estimate = data[\"avg_treated_response\"]\n",
    "    se = data[\"treated_se\"]\n",
    "    conf_lower = estimate - z_value * se\n",
    "    conf_upper = estimate + z_value * se\n",
    "\n",
    "    return get_model_inferences(data, estimate, se, conf_lower, conf_upper)\n",
    "\n",
    "\n",
    "def get_difference_inferences(data, alpha=0.05):\n",
    "    z_value = stats.norm.ppf(1 - alpha / 2)\n",
    "    estimate = data[\"avg_treated_response\"] - data[\"avg_control_response\"]\n",
    "    se = np.sqrt(data[\"treated_se\"] ** 2 + data[\"control_se\"] ** 2)\n",
    "    conf_lower = estimate - z_value * se\n",
    "    conf_upper = estimate + z_value * se\n",
    "\n",
    "    return get_model_inferences(data, estimate, se, conf_lower, conf_upper)\n",
    "\n",
    "\n",
    "def get_posterior_inferences(model, data, alpha=0.05):\n",
    "    fit = model.sample(data=data, iter_sampling=1000, show_progress=False)\n",
    "    estimate = np.mean(fit.stan_variable(\"theta\"), axis=0)\n",
    "    se = np.std(fit.stan_variable(\"theta\"), axis=0)\n",
    "\n",
    "    thetas = fit.stan_variable(\"theta\")\n",
    "    conf_lower = np.quantile(thetas, alpha / 2, axis=0)\n",
    "    conf_upper = np.quantile(thetas, 1 - alpha / 2, axis=0)\n",
    "\n",
    "    return get_model_inferences(data, estimate, se, conf_lower, conf_upper)\n",
    "\n",
    "\n",
    "def get_summary(df):\n",
    "    prop_signif = np.mean(df[\"is_signif\"])\n",
    "    mse = np.mean(df[\"error\"] ** 2)\n",
    "    type_s_rate = (\n",
    "        len(df[df[\"is_signif\"] & ~df[\"correct_sign\"]]) / len(df) if len(df) > 0 else 0\n",
    "    )\n",
    "    return {\n",
    "        \"prop_signif\": prop_signif,\n",
    "        \"type_s_rate\": type_s_rate,\n",
    "        \"mse\": mse,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_inferences(\n",
    "    model,\n",
    "    num_repetitions,\n",
    "    num_subjects_per_expt,\n",
    "    prop_treatment,\n",
    "    mu_b,\n",
    "    mu_theta,\n",
    "    sigma_b,\n",
    "    sigma_theta,\n",
    "    sigma_treatment,\n",
    "    sigma_control,\n",
    "    show_progress=False,\n",
    "):\n",
    "    summaries = {\n",
    "        method: {\"prop_signif\": [], \"type_s_rate\": [], \"mse\": []}\n",
    "        for method in [\"exposed_only\", \"difference\", \"posterior\"]\n",
    "    }\n",
    "\n",
    "    for i in range(num_repetitions):\n",
    "        fake_data = fake_expts_with_prop(\n",
    "            num_subjects_per_expt,\n",
    "            prop_treatment,\n",
    "            mu_b,\n",
    "            mu_theta,\n",
    "            sigma_b,\n",
    "            sigma_theta,\n",
    "            sigma_treatment,\n",
    "            sigma_control,\n",
    "        )\n",
    "\n",
    "        exposed_only = get_exposed_only_inferences(fake_data)\n",
    "        difference = get_difference_inferences(fake_data)\n",
    "        posterior = get_posterior_inferences(model, fake_data)\n",
    "\n",
    "        for method, df in zip(\n",
    "            [\"exposed_only\", \"difference\", \"posterior\"],\n",
    "            [exposed_only, difference, posterior],\n",
    "        ):\n",
    "            summary = get_summary(df)\n",
    "            for key in summary:\n",
    "                summaries[method][key].append(summary[key])\n",
    "\n",
    "        if show_progress and i % 10 == 0:\n",
    "            print(f\"Completed repetition {i} of {num_repetitions - 1}\")\n",
    "\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_expts = 38\n",
    "num_subjects_per_expt = np.repeat(64, num_expts)\n",
    "\n",
    "const_prop = np.linspace(0.5, 0.05, 38)  # constant proportion treated\n",
    "varying_prop = np.linspace(0.5, 0.95, 38)  # increase from 0.5 to 1 linearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed repetition 1 of 200\n",
      "Completed repetition 11 of 200\n",
      "Completed repetition 21 of 200\n",
      "Completed repetition 31 of 200\n",
      "Completed repetition 41 of 200\n",
      "Completed repetition 51 of 200\n",
      "Completed repetition 61 of 200\n",
      "Completed repetition 71 of 200\n",
      "Completed repetition 81 of 200\n",
      "Completed repetition 91 of 200\n",
      "Completed repetition 101 of 200\n",
      "Completed repetition 111 of 200\n",
      "Completed repetition 121 of 200\n",
      "Completed repetition 131 of 200\n",
      "Completed repetition 141 of 200\n",
      "Completed repetition 151 of 200\n",
      "Completed repetition 161 of 200\n",
      "Completed repetition 171 of 200\n",
      "Completed repetition 181 of 200\n",
      "Completed repetition 191 of 200\n"
     ]
    }
   ],
   "source": [
    "const_prop_results = repeat_inferences(\n",
    "    model=CmdStanModel(stan_file=\"dynamic_hier.stan\"),\n",
    "    num_repetitions=200,\n",
    "    num_subjects_per_expt=num_subjects_per_expt,\n",
    "    prop_treatment=const_prop,\n",
    "    mu_b=0,\n",
    "    mu_theta=chick_fit.theta.mean(),\n",
    "    sigma_b=np.std(np.mean(chick_fit.b, axis=0)),\n",
    "    sigma_theta=np.std(np.mean(chick_fit.theta, axis=0)),\n",
    "    sigma_treatment=(32**0.5) * 0.04,\n",
    "    sigma_control=(32**0.5) * 0.04,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed repetition 1 of 200\n",
      "Completed repetition 11 of 200\n",
      "Completed repetition 21 of 200\n",
      "Completed repetition 31 of 200\n",
      "Completed repetition 41 of 200\n",
      "Completed repetition 51 of 200\n",
      "Completed repetition 61 of 200\n",
      "Completed repetition 71 of 200\n",
      "Completed repetition 81 of 200\n",
      "Completed repetition 91 of 200\n",
      "Completed repetition 101 of 200\n",
      "Completed repetition 111 of 200\n",
      "Completed repetition 121 of 200\n",
      "Completed repetition 131 of 200\n",
      "Completed repetition 141 of 200\n",
      "Completed repetition 151 of 200\n",
      "Completed repetition 161 of 200\n",
      "Completed repetition 171 of 200\n",
      "Completed repetition 181 of 200\n",
      "Completed repetition 191 of 200\n"
     ]
    }
   ],
   "source": [
    "varying_prop_results = repeat_inferences(\n",
    "    model=CmdStanModel(stan_file=\"dynamic_hier.stan\"),\n",
    "    num_repetitions=200,\n",
    "    num_subjects_per_expt=num_subjects_per_expt,\n",
    "    prop_treatment=varying_prop,\n",
    "    mu_b=0,\n",
    "    mu_theta=chick_fit.theta.mean(),\n",
    "    sigma_b=np.std(np.mean(chick_fit.b, axis=0)),\n",
    "    sigma_theta=np.std(np.mean(chick_fit.theta, axis=0)),\n",
    "    sigma_treatment=(32**0.5) * 0.04,\n",
    "    sigma_control=(32**0.5) * 0.04,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposed_only\n",
      "prop_signif\n",
      "Constant prop: 0.42236842105263156\n",
      "Varying prop: 0.6848684210526315\n",
      "type_s_rate\n",
      "Constant prop: 0.0035526315789473684\n",
      "Varying prop: 0.006973684210526315\n",
      "mse\n",
      "Constant prop: 0.007645530621790338\n",
      "Varying prop: 0.00431726538204074\n",
      "\n",
      "difference\n",
      "prop_signif\n",
      "Constant prop: 0.3434210526315789\n",
      "Varying prop: 0.34315789473684205\n",
      "type_s_rate\n",
      "Constant prop: 0.004210526315789474\n",
      "Varying prop: 0.004736842105263157\n",
      "mse\n",
      "Constant prop: 0.008768083582281384\n",
      "Varying prop: 0.008204222542839186\n",
      "\n",
      "posterior\n",
      "prop_signif\n",
      "Constant prop: 0.6698684210526317\n",
      "Varying prop: 0.7760526315789472\n",
      "type_s_rate\n",
      "Constant prop: 0.0\n",
      "Varying prop: 0.0005263157894736842\n",
      "mse\n",
      "Constant prop: 0.0016331201410843606\n",
      "Varying prop: 0.0020920571166903952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in [\"exposed_only\", \"difference\", \"posterior\"]:\n",
    "    print(method)\n",
    "    for key in [\"prop_signif\", \"type_s_rate\", \"mse\"]:\n",
    "        print(key)\n",
    "        const_prop_results[method][key] = np.mean(const_prop_results[method][key])\n",
    "        varying_prop_results[method][key] = np.mean(varying_prop_results[method][key])\n",
    "\n",
    "        print(f\"Constant prop: {const_prop_results[method][key]}\")\n",
    "        print(f\"Varying prop: {varying_prop_results[method][key]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicks_avg_subjects = math.floor(np.mean(chicks[\"exposed_n\"] + chicks[\"sham_n\"]))\n",
    "chick_mu_b = chick_fit.stan_variable(\"b\").mean()\n",
    "chick_mu_theta = chick_fit.stan_variable(\"theta\").mean()\n",
    "chick_se = (32**0.5) * 0.04\n",
    "\n",
    "balanced_sim = fake_expts_with_prop(\n",
    "    num_subjects_per_expt=np.repeat(chicks_avg_subjects, len(chicks)),\n",
    "    prop_treatment=np.repeat(0.5, len(chicks)),\n",
    "    mu_b=0,\n",
    "    mu_theta=chick_mu_theta,\n",
    "    sigma_b=np.std(np.mean(chick_fit.stan_variable(\"b\"), axis=0)),\n",
    "    sigma_theta=np.std(np.mean(chick_fit.stan_variable(\"theta\"), axis=0)),\n",
    "    sigma_treatment=chick_se,\n",
    "    sigma_control=chick_se,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
