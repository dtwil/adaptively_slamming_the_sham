{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from cmdstanpy import CmdStanModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we repeat the analysis that was done in the original simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>sham_n</th>\n",
       "      <th>sham_est</th>\n",
       "      <th>sham_se</th>\n",
       "      <th>exposed_n</th>\n",
       "      <th>exposed_est</th>\n",
       "      <th>exposed_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.041</td>\n",
       "      <td>32</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.042</td>\n",
       "      <td>36</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>32</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.032</td>\n",
       "      <td>32</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.040</td>\n",
       "      <td>32</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq  sham_n  sham_est  sham_se  exposed_n  exposed_est  exposed_se\n",
       "0     1      32    -0.005    0.041         32        0.036       0.041\n",
       "1    15      32     0.013    0.042         36        0.173       0.034\n",
       "2    30      32     0.033    0.032         32        0.107       0.035\n",
       "3    45      32    -0.010    0.032         32        0.181       0.052\n",
       "4    60      32    -0.002    0.040         32        0.136       0.044"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicks = pd.read_table(\"chickens.dat\", sep=\"\\\\s+\")\n",
    "chicks[\"exposed_est\"] -= 1\n",
    "chicks[\"sham_est\"] -= 1\n",
    "chicks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:18:29 - cmdstanpy - INFO - CmdStan start processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9914eac153c94c489f7a152d05f55a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2347dda06564412a9bf728d718cec90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a38c051a74748d59b8b55b7bf487b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dcd5796dad430da3685adcfd69b5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:18:30 - cmdstanpy - INFO - CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chick_model = CmdStanModel(stan_file=\"dynamic_hier.stan\")\n",
    "chick_data = {\n",
    "    \"num_expts\": len(chicks),\n",
    "    \"avg_treated_response\": chicks[\"exposed_est\"],\n",
    "    \"avg_control_response\": chicks[\"sham_est\"],\n",
    "    \"treated_se\": chicks[\"exposed_se\"],\n",
    "    \"control_se\": chicks[\"sham_se\"],\n",
    "    \"expt_id\": list(range(1, len(chicks) + 1)),\n",
    "}\n",
    "chick_fit = chick_model.sample(data=chick_data, adapt_delta=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below simulates a dataset for `num_experiments` experiments, all assumed to have the same proportion `prop_treatment` allocated to the treatment group. Here one complication is that the original simulation assumes all experiments have the same number of subjects in the control and treatment groups.\n",
    "\n",
    "The original assumptions are:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    y_{j1} \\mid \\theta_j, b_j &\\sim N(\\theta_j + b_j, s_{j1}) \\\\\n",
    "    y_{j0} \\mid b_j &\\sim N(b_j, s_{j0}) \\\\\n",
    "    \\theta_j &\\sim N(\\mu_\\theta, \\sigma_\\theta) \\\\\n",
    "    b_j &\\sim N(\\mu_b, \\sigma_b)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "These assumptions mostly still work here since $s_{j1}$ and $s_{j0}$ need not be the same for all experiments $j$. However, in the original simulation, it was assumed that $s_{j1} = s_{j0} = 0.04$ for all $j$. This is reasonable if the treatment and control groups have the same size and if we expect the treatment/sham effects to have similar spread, which was empirically shown for the chicken dataset. \n",
    "\n",
    "However, if the groups have unequal numbers of subjects, then we expect the group with fewer subjects to have higher variance. We let $Y_{j0}^{(i)}$ and $Y_{j1}^{(k)}$ be the outcomes for the $i$-th and $k$-th individuals in the control and treatment groups respectively for experiment $j$. Let the $j$-th experiment have $N_{j0}$ and $N_{j1}$ subjects in control and treatment groups respectively. If the number of subjects in each group is at least 30, then assuming the individual outcomes are iid, the CLT gives\n",
    "\n",
    "$$ y_{j1} = \\frac{1}{N_{j1}} \\sum_{k=1}^{N_{j1}} Y_{j1}^{(k)} \\rightarrow N(\\mu_{j1}, \\sigma_{j1}) $$\n",
    "\n",
    "where $\\sigma_{j1} = \\sqrt{\\frac{\\text{var}(Y_{j1})}{N_{j1}}}$ and similarly for $y_{j0}$. We identify $\\mu_{j1}$ with $\\theta_j + b_j$ and $\\sigma_{j1}$ with $s_{j1}$. Since $s_{j1} = 0.04$ in the original simulation, we use $\\text{var}(Y_{j1}) = 32 \\times (0.04)^2$ for all experiments $j$; likewise for $\\text{var}(Y_{j0})$.\n",
    "\n",
    "*Thought: What if the sample sizes are too small for the CLT? Maybe bootstrap or make distributional assumptions on $Y_{j1}^{(k)}$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_expts_with_prop(\n",
    "    num_subjects_per_expt,\n",
    "    prop_treatment,\n",
    "    mu_b,\n",
    "    mu_theta,\n",
    "    sigma_b,\n",
    "    sigma_theta,\n",
    "    sigma_treatment,\n",
    "    sigma_control,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic data with a specified proportion of treated subjects.\n",
    "\n",
    "    Args:\n",
    "    num_subjects_per_expt: A list of integers, the number of subjects in each\n",
    "        experiment.\n",
    "    prop_treatment: A float, the proportion of subjects that are treated.\n",
    "    mu_b: A float, the true (mean) of the control group response.\n",
    "    mu_theta: A float, the true (mean) treatment effect.\n",
    "    sigma_b: A float, the standard deviation of b_j.\n",
    "    sigma_theta: A float, the standard deviation of theta_j.\n",
    "    sigma_treatment: A float, the standard deviation of the treated group\n",
    "        response.\n",
    "    sigma_control: A float, the standard deviation of the control group\n",
    "        response.\n",
    "    \"\"\"\n",
    "    assert len(num_subjects_per_expt) == len(prop_treatment)\n",
    "    assert sigma_theta >= 0 and sigma_b >= 0\n",
    "    assert sigma_treatment >= 0 and sigma_control >= 0\n",
    "\n",
    "    num_expts = len(num_subjects_per_expt)\n",
    "    num_treated = np.floor(prop_treatment * num_subjects_per_expt).astype(int)\n",
    "    num_control = num_subjects_per_expt - num_treated\n",
    "\n",
    "    sigma_y1 = sigma_treatment / np.sqrt(num_treated)\n",
    "    sigma_y0 = sigma_control / np.sqrt(num_control)\n",
    "\n",
    "    theta = np.random.normal(mu_theta, sigma_theta, num_expts)\n",
    "    b = np.random.normal(mu_b, sigma_b, num_expts)\n",
    "\n",
    "    return {\n",
    "        \"true_params\": {\n",
    "            \"mu_b\": mu_b,\n",
    "            \"mu_theta\": mu_theta,\n",
    "            \"sigma_b\": sigma_b,\n",
    "            \"sigma_theta\": sigma_theta,\n",
    "            \"sigma_treatment\": sigma_treatment,\n",
    "            \"sigma_control\": sigma_control,\n",
    "        },\n",
    "        \"num_expts\": len(num_subjects_per_expt),\n",
    "        \"avg_treated_response\": np.random.normal(theta + b, sigma_y1),\n",
    "        \"avg_control_response\": np.random.normal(b, sigma_y0),\n",
    "        \"treated_se\": sigma_y1,\n",
    "        \"control_se\": sigma_y0,\n",
    "        \"expt_id\": list(range(1, num_expts + 1)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statistics(model, data, alpha=0.05):\n",
    "    fit = model.sample(data=data, iter_sampling=1000)\n",
    "\n",
    "    # Get estimated theta_j and b_j from the posterior for each experiment j\n",
    "    theta_j_hat = np.mean(fit.stan_variable(\"theta\"), axis=0)\n",
    "    b_j_hat = np.mean(fit.stan_variable(\"b\"), axis=0)\n",
    "\n",
    "    summary = {\n",
    "        # estimate 1: theta_j = y_1\n",
    "        \"exposed_only\": {\n",
    "            \"estimates\": data[\"avg_treated_response\"],\n",
    "            \"se\": data[\"treated_se\"],\n",
    "        },\n",
    "        # estimate 2: theta_j = y_1 - y_0\n",
    "        \"difference\": {\n",
    "            \"estimates\": data[\"avg_treated_response\"] - data[\"avg_control_response\"],\n",
    "            \"se\": np.sqrt(data[\"treated_se\"] ** 2 + data[\"control_se\"] ** 2),\n",
    "        },\n",
    "        # estimate 3: theta_j averaged from posterior\n",
    "        \"posterior\": {\n",
    "            \"estimates\": theta_j_hat,\n",
    "            \"se\": np.std(fit.stan_variable(\"theta\"), axis=0),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    z_value = stats.norm.ppf(1 - alpha / 2)\n",
    "    for method in summary:\n",
    "        estimate = summary[method][\"estimates\"]\n",
    "        se = summary[method][\"se\"]\n",
    "\n",
    "        if method == \"posterior\":\n",
    "            conf_interval = np.percentile(\n",
    "                fit.stan_variable(\"theta\"), [alpha / 2, 1 - alpha / 2], axis=0\n",
    "            ).T\n",
    "        else:\n",
    "            conf_interval = np.column_stack(\n",
    "                [estimate - z_value * se, estimate + z_value * se]\n",
    "            )\n",
    "\n",
    "        summary[method][\"conf_interval\"] = conf_interval\n",
    "        summary[method][\"significant\"] = (0 < conf_interval[:, 0]) | (\n",
    "            conf_interval[:, 1] < 0) # 0 is not in the interval\n",
    "        summary[method][\"proportion_significant\"] = np.mean(\n",
    "            summary[method][\"significant\"]\n",
    "        )\n",
    "        summary[method][\"mse\"] = np.mean(\n",
    "            (data[\"true_params\"][\"mu_theta\"] - estimate) ** 2\n",
    "        )\n",
    "\n",
    "        correct_sign = np.sign(data[\"true_params\"][\"mu_theta\"]) == np.sign(estimate)\n",
    "        if summary[method][\"proportion_significant\"] > 0:\n",
    "            summary[method][\"type_s_rate\"] = (\n",
    "                np.mean(summary[method][\"significant\"] * (1 - correct_sign))\n",
    "                / summary[method][\"proportion_significant\"]\n",
    "            )\n",
    "        else:\n",
    "            summary[method][\"type_s_rate\"] = 0\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicks_avg_subjects = math.floor(np.mean(chicks[\"exposed_n\"] + chicks[\"sham_n\"]))\n",
    "chick_mu_b = chick_fit.stan_variable(\"b\").mean()\n",
    "chick_mu_theta = chick_fit.stan_variable(\"theta\").mean()\n",
    "chick_se = (32 ** 0.5) * 0.04\n",
    "\n",
    "balanced_sim = fake_expts_with_prop(\n",
    "    num_subjects_per_expt=np.repeat(chicks_avg_subjects, len(chicks)),\n",
    "    prop_treatment=np.repeat(0.5, len(chicks)),\n",
    "    mu_b=0,\n",
    "    mu_theta=chick_mu_theta,\n",
    "    sigma_b=np.std(np.mean(chick_fit.stan_variable(\"b\"), axis=0)),\n",
    "    sigma_theta=np.std(np.mean(chick_fit.stan_variable(\"theta\"), axis=0)),\n",
    "    sigma_treatment=chick_se,\n",
    "    sigma_control=chick_se,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:45:28 - cmdstanpy - INFO - CmdStan start processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cd1135b7604fd3b1e25bf18d5bd222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32517687b7ac4d9b908400f3b2ea1457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d74ce731bf44cfb0a42c8f4c73a643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc58ad3b68aa4013891e1d1b06fe31bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:45:28 - cmdstanpy - INFO - CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "balanced_summary = extract_statistics(chick_model, balanced_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposed_only:\n",
      "  Proportion significant: 0.7368421052631579\n",
      "  Type S rate: 0.0\n",
      "  MSE: 0.005522370330274892\n",
      "\n",
      "difference:\n",
      "  Proportion significant: 0.6578947368421053\n",
      "  Type S rate: 0.0\n",
      "  MSE: 0.0061962700993545014\n",
      "\n",
      "posterior:\n",
      "  Proportion significant: 0.8421052631578947\n",
      "  Type S rate: 0.0\n",
      "  MSE: 0.0029993185161740657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in balanced_summary:\n",
    "    print(f\"{method}:\")\n",
    "    print(f\"  Proportion significant: {balanced_summary[method]['proportion_significant']}\")\n",
    "    print(f\"  Type S rate: {balanced_summary[method]['type_s_rate']}\")\n",
    "    print(f\"  MSE: {balanced_summary[method]['mse']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "first_half = len(chicks) // 2\n",
    "second_half = len(chicks) - first_half\n",
    "\n",
    "num_subjects = np.concatenate([np.repeat(chicks_avg_subjects, first_half), \n",
    "    np.repeat(chicks_avg_subjects, second_half)])\n",
    "imbalanced_prop = np.concatenate([np.repeat(0.95, first_half), np.repeat(0.7, second_half)])\n",
    "\n",
    "print(len(imbalanced_prop))\n",
    "print(len(num_subjects))\n",
    "\n",
    "imbalanced_sim = fake_expts_with_prop(\n",
    "    num_subjects_per_expt=num_subjects,\n",
    "    prop_treatment=imbalanced_prop,\n",
    "    mu_b=0,\n",
    "    mu_theta=chick_mu_theta,\n",
    "    sigma_b=np.std(np.mean(chick_fit.stan_variable(\"b\"), axis=0)),\n",
    "    sigma_theta=np.std(np.mean(chick_fit.stan_variable(\"theta\"), axis=0)),\n",
    "    sigma_treatment=chick_se,\n",
    "    sigma_control=chick_se,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:46:23 - cmdstanpy - INFO - CmdStan start processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938fbc1b0d4d4127979308b114bdc349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ad5593d96b49f8854bc9f7eaa56db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314ebaec42054658ae38567ba4162220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acf05bb891145539727a2ca0d1d12ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:46:24 - cmdstanpy - INFO - CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "imbalanced_summary = extract_statistics(chick_model, imbalanced_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposed_only:\n",
      "  Proportion significant: 29.0\n",
      "  Type S rate: 0.0\n",
      "  MSE: 0.003682709970192089\n",
      "\n",
      "difference:\n",
      "  Proportion significant: 13.0\n",
      "  Type S rate: 0.07692307692307691\n",
      "  MSE: 0.012096909439819893\n",
      "\n",
      "posterior:\n",
      "  Proportion significant: 29.0\n",
      "  Type S rate: 0.0\n",
      "  MSE: 0.0016399451990699618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in imbalanced_summary:\n",
    "    print(f\"{method}:\")\n",
    "    print(f\"  Proportion significant: {len(num_subjects) * imbalanced_summary[method]['proportion_significant']}\")\n",
    "    print(f\"  Type S rate: {imbalanced_summary[method]['type_s_rate']}\")\n",
    "    print(f\"  MSE: {imbalanced_summary[method]['mse']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
