{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cmdstanpy import CmdStanModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we repeat the analysis that was done in the original simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/h3lz2z7j14j7hndqzb5_3cth0000gn/T/ipykernel_52030/297034283.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_table is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  chicks = pd.read_table(\"chickens.dat\", delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "chicks = pd.read_table(\"chickens.dat\", delim_whitespace=True)\n",
    "J = len(chicks)\n",
    "x = chicks[\"freq\"]\n",
    "y0 = chicks[\"sham_est\"] - 1\n",
    "se0 = chicks[\"sham_se\"]\n",
    "n0 = chicks[\"sham_n\"]\n",
    "y1 = chicks[\"exposed_est\"] - 1\n",
    "se1 = chicks[\"exposed_se\"]\n",
    "n1 = chicks[\"exposed_n\"]\n",
    "diff = y1 - y0\n",
    "diff_se = np.sqrt(se1**2 + se0**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Stan model\n",
    "y = list(y0) + list(y1)\n",
    "se = list(se0) + list(se1)\n",
    "expt_id = list(range(1, J + 1)) + list(range(1, J + 1))\n",
    "z = J * [0] + J * [1]  # treatment: 0 = sham, 1 = exposed\n",
    "chick_data = {\n",
    "    \"N\": 2 * J,\n",
    "    \"J\": J,\n",
    "    \"y\": y,\n",
    "    \"se\": se,\n",
    "    \"x\": x,\n",
    "    \"expt_id\": expt_id,\n",
    "    \"z\": z,\n",
    "    \"diff\": list(diff),\n",
    "    \"diff_se\": list(diff_se),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CmdStanModel(stan_file=\"chickens-no-corr-hier.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:33:39 - cmdstanpy - INFO - CmdStan start processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5163c86e80445f9ca6b94e006b188f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 1 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531688e84c7946d285e7bfa7ae7e50e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 2 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5885e8d0da2405dbb17aaa01dc0a2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 3 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c39d0aebb3d402bb2c0bc11194c2854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chain 4 |          | 00:00 Status"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:33:40 - cmdstanpy - INFO - CmdStan done processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit = model.sample(data=chick_data, adapt_delta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = fit.stan_variable(\"theta\")\n",
    "theta_mean = np.mean(theta, axis=0)\n",
    "theta_se = np.std(theta, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below simulates a dataset for `num_experiments` experiments, all assumed to have the same proportion `prop_treatment` allocated to the treatment group. Here one complication is that the original simulation assumes all experiments have the same number of subjects in the control and treatment groups.\n",
    "\n",
    "The original assumptions are:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    y_{j1} &\\sim N(\\theta_j + b_j, s_{j1}) \\\\\n",
    "    y_{j0} &\\sim N(b_j, s_{j0}) \\\\\n",
    "    \\theta_j &\\sim N(\\mu_\\theta, \\sigma_\\theta) \\\\\n",
    "    b_j &\\sim N(\\mu_b, \\sigma_b)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "These assumptions mostly still work here since $s_{j1}$ and $s_{j0}$ need not be the same for all experiments $j$. However, in the original simulation, it was assumed that $s_{j1} = s_{j0} = 0.04$ for all $j$. This is reasonable if the treatment and control groups have the same size and if we expect the treatment/sham effects to have similar spread, which was empirically shown for the chicken dataset. \n",
    "\n",
    "However, if the groups have unequal numbers of subjects, then we expect the group with fewer subjects to have higher variance. We let $Y_{j0}^{(i)}$ and $Y_{j1}^{(k)}$ be the outcomes for the $i$-th and $k$-th individuals in the control and treatment groups respectively for experiment $j$. Let the $j$-th experiment have $N_{j0}$ and $N_{j1}$ subjects in control and treatment groups respectively. If the number of subjects in each group is at least 30, then by the CLT we have\n",
    "\n",
    "$$ y_{j1} = \\frac{1}{N_{j1}} \\sum_{k=1}^{N_{j1}} Y_{j1}^{(k)} \\rightarrow N(\\mu_{j1}, \\sigma_{j1}) $$\n",
    "\n",
    "where $\\sigma_{j1} = \\sqrt{\\frac{\\text{var}(Y_{j1}^{(k)})}{N_{j1}}}$ and similarly for $y_{j0}$. We identify $\\mu_{j1}$ with $\\theta_j + b_j$ and $\\sigma_{j1}$ with $s_{j1}$. Since $s_{j1} = 0.04$ in the original simulation, we use $\\text{var}(Y_{j1}^{(k)}) = 32 \\times (0.04)^2$ for all experiments $j$ and individuals $k$; likewise for $\\text{var}(Y_{j0}^{(i)})$.\n",
    "\n",
    "*Thought: What if the sample sizes are too small for the CLT? Maybe bootstrap or make distributional assumptions on $Y_{j1}^{(k)}$?*\n",
    "\n",
    "Here is a more general treatment. Assuming random allocation between groups, it seems reasonable to model \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Y_{j1}^{(k)} \\overset{\\mathrm{iid}}{\\sim} F_{j1}, \\quad \\forall k = 1, \\ldots, N_{j1} \\\\\n",
    "    Y_{j0}^{(k)} \\overset{\\mathrm{iid}}{\\sim} F_{j0}, \\quad \\forall k = 1, \\ldots, N_{j0}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "for some distributions $F_{j1}$ and $F_{j0}$. In practice, we expect these distributions to vary over $j$ due to differences in the experimental setup or sampling from different populations (intentional or not). However, we make the simplifying assumption that $F_{j1} = F_1$ and $F_{j0} = F_0$ for all experiments $j$.\n",
    "\n",
    "Further, we assume\n",
    "$$\n",
    "\\begin{align}\n",
    "    F_1 &= N(\\mu_1, \\sigma_1) \\\\\n",
    "    F_0 &= N(\\mu_0, \\sigma_0)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is reasonable if $N_{j1} \\geq 30$ and $N_{j0} \\geq 30$ for all $j$, as discussed above. This yields\n",
    "\n",
    "$$y_{j1} = \\frac{1}{N_{j1}} \\sum_{k=1}^{N_{j1}} \\sim N(\\mu_1, \\sigma_1 / \\sqrt{ N_{ j1 } } })$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.03726713045384946)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_experiments(\n",
    "    num_experiments,\n",
    "    num_subjects_per_experiment,\n",
    "    prop_treatment,\n",
    "    true_b,\n",
    "    true_theta,\n",
    "    sigma_b,\n",
    "    sigma_theta,\n",
    "    sigma_treatment,\n",
    "    sigma_control,\n",
    "):\n",
    "    num_treated = np.floor(prop_treatment * num_subjects_per_experiment).astype(int)\n",
    "    num_control = num_subjects_per_experiment - num_treated\n",
    "\n",
    "    sigma_y0 = sigma_control / np.sqrt(num_control)\n",
    "    sigma_y1 = sigma_treatment / np.sqrt(num_treated)\n",
    "\n",
    "    b = np.random.normal(true_b, sigma_b, num_experiments)\n",
    "    theta = np.random.normal(true_theta, sigma_theta, num_experiments)\n",
    "    y_control = np.random.normal(b, sigma_y0)\n",
    "    y_treated = np.random.normal(theta + b, sigma_y1)\n",
    "\n",
    "    return {\n",
    "        \"num_\": 2 * num_experiments,\n",
    "        \"J\": num_experiments,\n",
    "        \"P\": prop_treatment,\n",
    "        \"y\": np.concatenate([y_control, y_treated]),\n",
    "        \"se\": np.concatenate([sigma_y0, sigma_y1]),\n",
    "        \"x\": np.ones(num_experiments),\n",
    "        \"expt_id\": np.tile(np.arange(1, num_experiments + 1), 2),\n",
    "        \"z\": np.concatenate([np.zeros(num_experiments), np.ones(num_experiments)]),\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
